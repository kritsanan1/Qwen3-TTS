# Thai-Isan TTS for Qwen3-TTS

## Overview

This project extends the Qwen3-TTS system to support **Thai** and **Isan** (Northeastern Thai) languages, creating the first comprehensive bilingual TTS system for these closely related but distinct languages.

### Key Features

- **Bilingual Support**: Thai (Central Thai) and Isan (Northeastern Thai)
- **Automatic Language Detection**: Detects language from input text
- **Phoneme Mapping**: Automatic conversion between Thai and Isan phonological systems
- **Tone System Support**: 5 tones for Thai, 6 tones for Isan
- **Regional Variants**: Support for different Isan dialects
- **Cultural Authenticity**: Maintains linguistic and cultural characteristics

## Background

### Thai Language
- **Speakers**: 60+ million native speakers
- **Script**: Thai alphabet (44 consonants, 15 vowel symbols)
- **Tones**: 5 phonemic tones
- **Region**: Central Thailand

### Isan Language
- **Speakers**: 13-16 million native speakers
- **Classification**: Southwestern Tai language, Lao variety
- **Tones**: 5-6 tones depending on dialect
- **Region**: Northeastern Thailand (Isan region)
- **Status**: Officially classified as Thai dialect, but linguistically distinct

### Linguistic Differences

| Feature | Thai | Isan |
|---------|------|------|
| /t…ï ∞/ sound | Present | ‚Üí /s/ (e.g., ‡∏ä‡πâ‡∏≤‡∏á ‚Üí ‡∏™‡πâ‡∏≤‡∏á) |
| /r/ sound | Common | ‚Üí /h/ or /l/ (e.g., ‡∏£‡πâ‡∏≠‡∏ô ‚Üí ‡∏Æ‡πâ‡∏≠‡∏ô) |
| /…≤/ vs /j/ | Merged | Maintained distinction |
| Vowels | /…Ø/, /…§/ | Centralized /…®/, /…ô/ |
| Tones | 5 tones | 5-6 tones (dialect-dependent) |
| Vocabulary | Central Thai | Lao-influenced vocabulary |

## Installation

### Prerequisites
```bash
# Python 3.8+
# PyTorch 1.12+
# Transformers 4.20+
# Librosa 0.9+
```

### Install Dependencies
```bash
pip install torch transformers librosa soundfile numpy scipy
pip install streamlit  # For demo interface
pip install jiwer    # For evaluation
```

### Clone Repository
```bash
git clone https://github.com/kritsanan1/Qwen3-TTS.git
cd Qwen3-TTS
```

## Usage

### Basic Usage

```python
from thai_isan_integration import create_thai_isan_tts

# Create TTS model
model = create_thai_isan_tts()

# Synthesize Thai speech
thai_text = "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö"
thai_audio = model.synthesize(thai_text, language="th")

# Synthesize Isan speech
isan_text = "‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏ö‡πà"
isan_audio = model.synthesize(isan_text, language="tts")
```

### Language Detection

```python
# Automatic language detection
text = "‡πÄ‡∏Æ‡∏≤‡πÑ‡∏õ‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß"  # Isan text
detected_lang = model.language_detector.detect_language(text)
print(f"Detected language: {detected_lang}")  # Output: tts

# Synthesize with auto-detection
audio = model.synthesize(text)  # Automatically detects as Isan
```

### Advanced Usage

```python
# Synthesize with prosody control
audio = model.synthesize(
    text="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
    language="th",
    speaker="th_male_central",
    prosody={
        "speed": 1.2,      # 20% faster
        "pitch": -0.5,     # Lower pitch
        "emotion": "happy" # Happy emotion
    }
)

# Get evaluation metrics
audio, evaluation = model.synthesize(
    text="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
    language="th",
    return_evaluation=True
)

print(f"Tone accuracy: {evaluation.language_specific_metrics['tone_accuracy']}")
print(f"Naturalness: {evaluation.subjective_scores['naturalness']}")
```

### Available Speakers

```python
# Thai speakers
thai_speakers = model.get_available_speakers("th")
print(thai_speakers)
# Output: ['th_male_central', 'th_female_central', 'th_male_northern', 'th_female_southern']

# Isan speakers
isan_speakers = model.get_available_speakers("tts")
print(isan_speakers)
# Output: ['tts_male_northeastern', 'tts_female_northeastern', 'tts_male_vientiane', 'tts_female_luang_prabang']
```

## Demo Interface

Run the interactive demo:

```bash
streamlit run thai_isan_demo.py
```

This opens a web interface where you can:
- Type text in Thai or Isan
- Select different speakers
- Adjust prosody (speed, pitch, emotion)
- Compare Thai vs Isan pronunciation
- Listen to synthesized speech
- Download audio files

## Training

### Data Requirements

- **Thai**: 100+ hours of high-quality speech
- **Isan**: 100+ hours covering all regional dialects
- **Speakers**: Minimum 50 speakers per language
- **Quality**: 48kHz sampling rate, studio-quality recordings

### Training Script

```python
from thai_isan_integration import train_thai_isan_tts

# Train new model
model_path = train_thai_isan_tts(
    train_data_path="./data/train",
    val_data_path="./data/val",
    output_dir="./output/thai_isan_tts",
    num_epochs=100,
    batch_size=32,
    learning_rate=2e-5
)

print(f"Model saved to: {model_path}")
```

## Evaluation

### Objective Metrics

```python
from thai_isan_evaluation import evaluate_thai_isan_tts

# Evaluate synthesized speech
metrics = evaluate_thai_isan_tts(
    synthesized_audio=audio,
    reference_audio=reference,
    text="‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
    language="th"
)

print(f"MCD: {metrics['mcd']}")
print(f"Tone accuracy: {metrics['tone_accuracy']}")
print(f"Naturalness: {metrics['naturalness']}")
```

### Supported Metrics

- **Spectral Quality**: MCD, F0 correlation, spectral convergence
- **Tone Accuracy**: Correct tone realization (95%+ target)
- **Phoneme Accuracy**: Correct phoneme pronunciation (<5% PER)
- **Naturalness**: MOS score (4.0+ target)
- **Cultural Authenticity**: Regional accent accuracy

## API Reference

### Core Classes

#### `Qwen3ThaiIsanTTS`
Main TTS model class with Thai-Isan support.

**Methods:**
- `synthesize(text, language, speaker, prosody)` - Synthesize speech
- `get_available_speakers(language)` - Get available speakers
- `get_supported_languages()` - Get supported languages
- `evaluate_text(text, language)` - Evaluate text characteristics

#### `ThaiIsanExtensionConfig`
Configuration for Thai-Isan language support.

**Attributes:**
- `supported_languages` - List of supported languages
- `thai_phonemes` - Thai phoneme inventory
- `isan_phonemes` - Isan phoneme inventory
- `thai_tones` - Thai tone system
- `isan_tones` - Isan tone system
- `isan_dialects` - Regional Isan dialects

#### `ThaiIsanTTSEvaluator`
Comprehensive evaluation framework.

**Methods:**
- `evaluate(synthesized, reference, text, language)` - Evaluate speech
- `compute_objective_metrics()` - Compute objective metrics
- `estimate_subjective_scores()` - Estimate subjective scores

### Configuration

#### Language Settings
```python
config = ThaiIsanExtensionConfig(
    supported_languages=["th", "tts"],
    thai_tones=["mid", "low", "falling", "high", "rising"],
    isan_tones=["mid", "low", "falling", "high", "rising", "high_falling"],
    isan_dialects=["northern", "central", "southern", "western"]
)
```

#### Training Configuration
```python
config.training_config = {
    "batch_size": 32,
    "learning_rate": 2e-5,
    "num_epochs": 100,
    "loss_weights": {
        "thai": 1.0,
        "isan": 1.2,  # Higher for minority language
        "tone": 2.0   # Emphasize tone accuracy
    }
}
```

## Examples

### Example 1: Basic Synthesis
```python
from thai_isan_integration import create_thai_isan_tts

model = create_thai_isan_tts()

# Thai synthesis
audio = model.synthesize("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", language="th")

# Isan synthesis  
audio = model.synthesize("‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏ö‡πà", language="tts")
```

### Example 2: Multi-speaker Synthesis
```python
# Different Thai speakers
for speaker in model.get_available_speakers("th"):
    audio = model.synthesize("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", language="th", speaker=speaker)
    print(f"Generated audio for speaker: {speaker}")

# Different Isan speakers
for speaker in model.get_available_speakers("tts"):
    audio = model.synthesize("‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏ö‡πà", language="tts", speaker=speaker)
    print(f"Generated audio for speaker: {speaker}")
```

### Example 3: Prosody Control
```python
# Happy emotion, faster speed
audio = model.synthesize(
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
    language="th",
    prosody={
        "emotion": "happy",
        "speed": 1.2,
        "pitch": 0.5
    }
)

# Sad emotion, slower speed
audio = model.synthesize(
    "‡πÄ‡∏Æ‡∏≤‡πÑ‡∏õ‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß",
    language="tts",
    prosody={
        "emotion": "sad",
        "speed": 0.8,
        "pitch": -0.3
    }
)
```

### Example 4: Language Detection and Conversion
```python
# Auto-detect language
texts = ["‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡πÄ‡∏Æ‡∏≤‡πÑ‡∏õ‡∏Å‡∏¥‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß", "‡∏ö‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à"]
for text in texts:
    lang = model.language_detector.detect_language(text)
    confidence = model.language_detector.get_language_confidence(text)
    print(f"Text: '{text}' -> Language: {lang} (confidence: {confidence:.3f})")
    
    # Synthesize with auto-detection
    audio = model.synthesize(text)  # Automatically detects language
```

### Example 5: Evaluation and Quality Control
```python
# Synthesize with evaluation
audio, evaluation = model.synthesize(
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
    language="th",
    return_evaluation=True
)

# Print evaluation results
print(f"Tone accuracy: {evaluation.language_specific_metrics['tone_accuracy']:.3f}")
print(f"Naturalness: {evaluation.subjective_scores['naturalness']:.3f}")
print(f"Spectral quality: {evaluation.objective_metrics['spectral_convergence']:.3f}")

# Detailed analysis
detailed_results = evaluation.detailed_results
print(f"Phoneme errors: {len(detailed_results['phoneme_errors'])}")
print(f"Tone analysis frames: {len(detailed_results['tone_analysis'])}")
```

## Technical Details

### Architecture

The system extends Qwen3-TTS with:

1. **Language Detection Module**: Automatically detects Thai vs Isan text
2. **Phoneme Mapper**: Converts between Thai and Isan phonological systems
3. **Tone Converter**: Handles different tonal systems (5 vs 6 tones)
4. **Regional Variants**: Supports different Isan dialects
5. **Cultural Context**: Maintains authentic linguistic features

### Phoneme Mapping

Key phonological differences:

```python
# Thai ‚Üí Isan conversions
THAI_TO_ISAN_MAPPING = {
    "t…ï ∞": "s",      # ‡∏ä‡πâ‡∏≤‡∏á ‚Üí ‡∏™‡πâ‡∏≤‡∏á
    "r": ["h", "l"], # ‡∏£‡πâ‡∏≠‡∏ô ‚Üí ‡∏Æ‡πâ‡∏≠‡∏ô
    "…Ø": "…®",        # Centralization
    "…§": "…ô",        # Centralization
    "j_context_…≤": "…≤"  # Maintain /…≤/ distinction
}
```

### Tone System

Thai and Isan have different tone realization rules:

```python
# Tone mapping between systems
TONE_MAPPING = {
    "thai": {
        "high_class_live": "rising",
        "mid_class_dead": "low",
        "low_class_long": "falling"
    },
    "isan": {
        "high_class_live": "high_falling",
        "mid_class_dead": "low", 
        "low_class_long": "rising"
    }
}
```

### Regional Variants

The system supports four main Isan dialects:

1. **Northern Isan** (Loei, Nong Khai): Influenced by Luang Prabang Lao
2. **Central Isan** (Khon Kaen, Kalasin): Standard Isan
3. **Southern Isan** (Ubon, Sisaket): Influenced by Pakse Lao
4. **Western Isan** (Nakhon Phanom, Sakon Nakhon): Close to Lao standard

## Performance

### Quality Targets

| Metric | Target | Description |
|--------|--------|-------------|
| Tone Accuracy | >95% | Correct tone realization |
| Phoneme Accuracy | >95% | Correct phoneme pronunciation |
| Naturalness (MOS) | >4.0 | Mean Opinion Score |
| Intelligibility | >4.0 | Ease of understanding |
| Authenticity | >3.8 | Cultural appropriateness |

### Speed Performance

- **Real-time synthesis**: <200ms latency
- **Batch processing**: 100x real-time
- **Memory usage**: <4GB GPU memory
- **CPU support**: Optimized for both CPU and GPU

## Limitations

1. **Data Requirements**: Requires substantial high-quality training data
2. **Regional Coverage**: May not cover all Isan sub-dialects
3. **Code-switching**: Limited support for mixed Thai-Isan text
4. **Emotional Range**: Basic emotional expression control
5. **Speaker Diversity**: Limited number of pre-trained speakers

## Future Work

### Short-term (3-6 months)
- Code-switching between Thai and Isan
- Improved emotional expression control
- Real-time voice conversion
- Mobile application

### Medium-term (6-12 months)
- Lao language support
- Northern/Southern Thai dialects
- Cross-lingual voice transfer
- Emotion-preserving translation

### Long-term (1+ years)
- Other Tai-Kadai languages (Shan, Tai Lue, etc.)
- Multilingual TTS with cultural adaptation
- Emotion-aware speech synthesis
- Personalized voice cloning

## Contributing

We welcome contributions to improve Thai-Isan TTS support:

1. **Data Collection**: Help collect high-quality speech data
2. **Linguistic Expertise**: Provide phonological and cultural insights
3. **Technical Development**: Improve model architecture and training
4. **Evaluation**: Help evaluate and validate the system
5. **Documentation**: Improve documentation and examples

## Citation

If you use this work in your research, please cite:

```bibtex
@software{thai_isan_tts_2024,
  title={Thai-Isan Text-to-Speech for Qwen3-TTS},
  author={Kritsanan and Contributors},
  year={2024},
  url={https://github.com/kritsanan1/Qwen3-TTS}
}
```

## License

This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Qwen team for the base Qwen3-TTS model
- Thai and Isan language communities for cultural insights
- Academic partners for linguistic expertise
- Open source community for tools and libraries

## Contact

For questions or collaboration:
- GitHub Issues: [Create an issue](https://github.com/kritsanan1/Qwen3-TTS/issues)
- Email: Available in GitHub profile
- Academic: Research collaboration welcome

---

**Supporting linguistic diversity in Southeast Asia through advanced AI technology.** üáπüá≠üåæ